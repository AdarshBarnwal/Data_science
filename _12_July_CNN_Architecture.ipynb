{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99161e2c-b8c8-45ac-bf30-72398c073163",
   "metadata": {},
   "source": [
    "## `Topic: understanding Pooling and padding in CNN: `\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f47a9eb-2fb1-4fbd-beb0-8344b2883e1f",
   "metadata": {},
   "source": [
    "### 1. `Describe the purpose and benefits of pooling in CNN.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9355382-dbc7-4468-9f09-c82a0bc5f878",
   "metadata": {},
   "source": [
    "`Purpose and Benefits of Pooling in CNN:`\n",
    "Pooling is a down-sampling operation commonly used in Convolutional Neural Networks (CNNs) to reduce the spatial dimensions of the feature maps while preserving important information. The main purposes and benefits of pooling are:\n",
    "\n",
    "-- `Spatial Down-Sampling:` Pooling reduces the size of the feature maps, making the model more computationally efficient and reducing the memory requirements. This is especially important when dealing with large images or deep architectures.\n",
    "\n",
    "-- `Translation Invariance:` Pooling makes the model more robust to slight translations of the object within the image. By selecting the most dominant features within a pooling window, the specific position of the feature becomes less critical, enhancing the model's ability to recognize objects irrespective of their location in the input.\n",
    "\n",
    "--`Feature Reduction:` Pooling helps to reduce the number of parameters and avoid overfitting. By discarding less significant details and retaining only the most important features, pooling encourages the model to focus on the most relevant information in the input.\n",
    "\n",
    "--`Increased Receptive Field:` Pooling helps to increase the receptive field of the neurons in deeper layers of the network. By reducing the spatial dimensions, neurons in deeper layers can capture information from a larger portion of the input image, facilitating the learning of more complex patterns and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac3643-bddd-4183-a61d-544b5d09d4a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b68ada45-1408-49de-a226-87c2727db18d",
   "metadata": {},
   "source": [
    "### 2. `Explain the difference between min pooling and max pooling.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987fcef3-9281-4184-9a2e-936eda55d720",
   "metadata": {},
   "source": [
    "Min pooling and max pooling are two types of pooling operations commonly used in Convolutional Neural Networks (CNNs) for down-sampling feature maps. Both pooling methods aim to reduce the spatial dimensions of the feature maps while preserving important information. However, they differ in how they select values within the pooling window.\n",
    "\n",
    "--`Max Pooling:`\n",
    "Max pooling is the most common type of pooling operation in CNNs.\n",
    "In max pooling, the maximum value within the pooling window is selected and retained, while all other values are discarded.\n",
    "Max pooling is used to focus on the most dominant features within the feature maps. By selecting the maximum value, it ensures that the most significant feature in the pooling window is preserved in the down-sampled feature map.\n",
    "Max pooling helps to enhance the model's ability to recognize important patterns and features in the input, making it more robust to slight variations in position or translation of objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27695393-ed35-4345-a418-17c602341827",
   "metadata": {},
   "outputs": [],
   "source": [
    "Example:\n",
    "Consider a 2x2 max pooling window applied to the following 4x4 input feature map:\n",
    "\n",
    "Input Feature Map:\n",
    "[ 1,  3,  2,  4]\n",
    "[ 6,  8,  9,  5]\n",
    "[12, 11, 10,  7]\n",
    "[16, 15, 14, 13]\n",
    "\n",
    "Max Pooling Output:\n",
    "[ 8,  9]\n",
    "[16, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3567a14-cc6d-405a-9dc3-9145ad777159",
   "metadata": {},
   "source": [
    "--`Min Pooling:`\n",
    "Min pooling is less common than max pooling and is not as widely used in CNNs.\n",
    "In min pooling, the minimum value within the pooling window is selected and retained, while all other values are discarded.\n",
    "Min pooling aims to focus on the least dominant features within the feature maps. By selecting the minimum value, it emphasizes the less significant features in the pooling window.\n",
    "Min pooling may not be as effective as max pooling in capturing important patterns and features, and it may not be as suitable for most computer vision tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8342914-12f5-4419-a5b3-75561ed1e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Example:\n",
    "Consider a 2x2 min pooling window applied to the same 4x4 input feature map as above:\n",
    "    \n",
    "Min Pooling Output:\n",
    "[ 1,  2]\n",
    "[12, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f753018d-85b7-4a33-a54c-eb4fdb636f01",
   "metadata": {},
   "source": [
    "Min pooling and max pooling are two common types of pooling operations in CNNs:\n",
    "\n",
    "`Max Pooling:` In max pooling, the maximum value within the pooling window is selected and retained, while the rest of the values are discarded. Max pooling is widely used as it helps the model focus on the most dominant features in the feature maps.\n",
    "\n",
    "`Min Pooling:` In min pooling, the minimum value within the pooling window is selected and retained. Min pooling is less common and not as popular as max pooling, as it may not capture the most relevant features in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada33c1-399a-4515-b299-71f2774ec8ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ab05a47-462c-4577-9b61-3fbed54f59fd",
   "metadata": {},
   "source": [
    "### 3. `Discuss the concept of padding in CNN and its significance.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca644ecd-f45f-42da-b995-ec9315f8f40b",
   "metadata": {},
   "source": [
    "Concept of Padding in CNN and Its Significance:\n",
    "\n",
    "Padding is the process of adding extra pixels around the borders of the input image or feature maps before applying convolution or pooling operations. The main significance of padding is to control the size of the output feature maps and preserve information at the edges of the input:\n",
    "\n",
    "`Avoiding Information Loss:` Without padding, convolutional and pooling operations reduce the spatial dimensions of the feature maps, leading to information loss at the edges. Padding helps retain the spatial dimensions and prevents the output feature maps from being smaller than the input.\n",
    "\n",
    "`Maintaining Spatial Information:` Padding ensures that the convolutional filters or pooling windows can be applied to all locations of the input image, even at the borders. This maintains the spatial information and allows the model to learn relevant features across the entire image.\n",
    "\n",
    "`There are two common types of padding:`\n",
    "\n",
    "a. `Zero-padding:` In zero-padding, extra pixels with a value of zero are added around the input image or feature map. Zero-padding is the most widely used type of padding and is preferred due to its simplicity and effectiveness.\n",
    "\n",
    "b. `Reflective padding:` In reflective padding (also called symmetric padding), the values at the border of the input are mirrored and extended beyond the boundary. This type of padding can be useful for certain applications but is less commonly used compared to zero-padding.\n",
    "\n",
    "In summary, padding is a crucial technique in CNNs that helps preserve spatial information, control the size of feature maps, and ensure that the convolutional and pooling operations produce accurate and meaningful representations of the input data. It plays a significant role in improving the performance and robustness of CNN models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373b6057-2bba-44a7-ac30-755337c523ca",
   "metadata": {},
   "source": [
    "### 4. `compare and contrast zero-padding and valid-padding in terms of their objects on the output feature map size.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f32315-6b7d-4161-a91c-aab99f36a79c",
   "metadata": {},
   "source": [
    "Zero-padding and valid-padding are two common types of padding used in Convolutional Neural Networks (CNNs),\n",
    "\n",
    "`Zero-padding:`\n",
    "\n",
    "-- Zero-padding involves adding extra pixels with a value of zero around the input image or feature map.\n",
    "\n",
    "-- With zero-padding, the spatial dimensions of the output feature map remain the same as the input or a specified size, depending on the amount of padding added.\n",
    "\n",
    "-- Zero-padding is especially useful when the goal is to maintain the spatial information and spatial size of the feature maps during convolution and pooling operations.\n",
    "\n",
    "-- For a given convolutional kernel size, the output feature map size is larger than the input size because of the added zero-pixels around the border.\n",
    "\n",
    "-- Zero-padding can help reduce the border effects and capture features accurately, especially at the edges of the input.\n",
    "\n",
    "--Zero-padding is commonly used in CNN architectures to ensure consistency in feature map sizes and enable better learning.\n",
    "\n",
    "`Valid-padding:`\n",
    "\n",
    "--Valid-padding involves no padding, which means no extra pixels are added around the input image or feature map.\n",
    "\n",
    "--With valid-padding, the spatial dimensions of the output feature map are reduced compared to the input, as the convolution kernel cannot be fully applied to the edges of the input.\n",
    "\n",
    "--Valid-padding is used when the goal is to reduce the spatial dimensions of the feature maps to extract more high-level and abstract features from the input.\n",
    "\n",
    "--For a given convolutional kernel size, the output feature map size is smaller than the input size because the convolution is restricted to the central pixels of the input.\n",
    "\n",
    "--Valid-padding is useful when the spatial information at the borders is less important, or when the objective is to downsample the feature maps for subsequent layers or tasks.\n",
    "\n",
    "--Valid-padding can help reduce the computational cost and memory requirements of the network since fewer operations are performed on the smaller feature maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acd3baf-ad4f-47d3-8702-1bb93a5288a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77efa77e-b213-42d3-8ded-5f898c518c14",
   "metadata": {},
   "source": [
    "## `TOPIC: Exploring LeNet.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d8d8f3-0fe4-4133-a245-5985dc183e3d",
   "metadata": {},
   "source": [
    "### 1. `Provide a brief overview of LeNet-5 architecture.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bcdafa-b4a4-4df7-ae56-8a97ad0b4445",
   "metadata": {},
   "source": [
    "LeNet-5 is a convolutional neural network (CNN) architecture designed by Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner in 1998. It is one of the pioneering CNNs and played a crucial role in advancing the field of computer vision and deep learning. LeNet-5 was specifically designed for handwritten digit recognition, and it demonstrated impressive performance on the MNIST dataset.\n",
    "\n",
    "The architecture of LeNet-5 consists of seven layers, including three convolutional layers, two subsampling (pooling) layers, and two fully connected layers. \n",
    "\n",
    "`Here's a brief overview of each layer:`\n",
    "\n",
    "`Input layer:` The input to LeNet-5 is a grayscale image of size 32x32 pixels. The network expects a fixed-size input, so the images in the MNIST dataset were centered in a 32x32 pixel canvas.\n",
    "\n",
    "`First Convolutional layer:` The first convolutional layer has six feature maps (also known as channels). Each feature map is obtained by applying a 5x5 convolutional filter to the input image. The output of this layer is a set of six 28x28 feature maps.\n",
    "\n",
    "`First Subsampling (Pooling) layer:` The first subsampling layer performs average pooling over non-overlapping 2x2 regions for each feature map. This reduces the spatial dimensions of the feature maps to half, resulting in six 14x14 feature maps.\n",
    "\n",
    "`Second Convolutional layer:` The second convolutional layer has 16 feature maps, each obtained by applying a 5x5 convolutional filter to the output of the first subsampling layer. The result is a set of 16 10x10 feature maps.\n",
    "\n",
    "`Second Subsampling (Pooling) layer:` Similar to the first pooling layer, the second pooling layer performs average pooling over non-overlapping 2x2 regions for each feature map, reducing their spatial dimensions to half. The output is 16 5x5 feature maps.\n",
    "\n",
    "`Fully Connected layer:` The fully connected layers act as a traditional neural network. The 16 5x5 feature maps are flattened into a vector and fed into a fully connected layer with 120 neurons.\n",
    "\n",
    "`Output layer:` The final fully connected layer has 84 neurons, and it is connected to the output layer with 10 neurons, representing the digits 0 to 9. The softmax activation function is used in the output layer to produce a probability distribution over the 10 classes.\n",
    "\n",
    "LeNet-5 is characterized by its simplicity and effectiveness in image classification tasks, especially for handwritten digit recognition. It laid the foundation for the development of more complex CNN architectures that are widely used today for a wide range of computer vision tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49de1cd-bf62-437e-a81c-91d65745b145",
   "metadata": {},
   "source": [
    "### 2. `Describe the key components of LeNet-5 and their respective purposes.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb9eca6-1cb9-4e55-a28a-ad012835b4cc",
   "metadata": {},
   "source": [
    "The key components of LeNet-5 and their respective purposes are as follows:\n",
    "\n",
    "`Convolutional Layers:` The first and second convolutional layers are the fundamental building blocks of LeNet-5. They are responsible for learning local patterns and features from the input images. Each convolutional layer applies a set of learnable filters (kernels) to the input feature maps, convolving them to create new feature maps. The purpose of these layers is to extract low-level features like edges, corners, and textures from the input images.\n",
    "\n",
    "`Subsampling (Pooling) Layers:` LeNet-5 includes two subsampling (pooling) layers after each convolutional layer. The pooling layers perform spatial down-sampling and help reduce the spatial dimensions of the feature maps while retaining their important features. The most commonly used pooling operation in LeNet-5 is average pooling, which calculates the average value within a small region (e.g., 2x2) of the feature map. Pooling aids in reducing the number of parameters in the network, making it computationally efficient.\n",
    "\n",
    "`Fully Connected Layers:` After the convolutional and pooling layers, LeNet-5 includes two fully connected layers. These layers act as a traditional neural network, where all neurons are connected to every neuron in the previous layer. The fully connected layers are responsible for combining the high-level features learned from the previous layers to make the final classification decision. In LeNet-5, the fully connected layers have 120 and 84 neurons, respectively, before connecting to the output layer.\n",
    "\n",
    "`Output Layer:` The output layer of LeNet-5 is a fully connected layer with 10 neurons, representing the 10 possible classes in the MNIST dataset (digits 0 to 9). The softmax activation function is applied to the output layer, which converts the raw scores into a probability distribution over the classes. The class with the highest probability is considered the final prediction.\n",
    "\n",
    "`Activation Functions:` Throughout LeNet-5, a common activation function used is the hyperbolic tangent (tanh) function. The tanh activation introduces non-linearity to the model, allowing it to learn complex relationships between features and making it more capable of capturing intricate patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e905e9f-0ade-424f-9307-a52d72e82b92",
   "metadata": {},
   "source": [
    "### 3. `Discuss the advantages and limitations of LeNet-5 in the context of image classification tasks.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b89972b-6649-47b9-8151-867f2ee584dc",
   "metadata": {},
   "source": [
    " `Advantages and limitations of LeNet-5:`\n",
    " \n",
    "   `Advantages:`\n",
    "   - LeNet-5 introduced the concept of CNNs, demonstrating their effectiveness in image classification tasks.\n",
    "   - It is relatively simple compared to modern CNN architectures, making it easy to understand and implement.\n",
    "   - LeNet-5 achieved state-of-the-art performance on the MNIST dataset and paved the way for more advanced CNNs.\n",
    "\n",
    "   `Limitations:`\n",
    "   - LeNet-5 may struggle with more complex and high-resolution datasets due to its limited depth and simplicity.\n",
    "   - The sigmoid activation function used in LeNet-5 can suffer from the vanishing gradient problem, slowing down convergence.\n",
    "   - Its performance may not be competitive with modern CNN architectures like ResNet, VGG, or Inception on large-scale image datasets.\n",
    "\n",
    "4. Implementation and evaluation of LeNet-5:\n",
    "   To implement LeNet-5, you can use popular deep learning frameworks like TensorFlow or PyTorch. Train it on a publicly available dataset such as MNIST, a dataset of handwritten digits. Evaluate its performance using metrics like accuracy, precision, recall, and F1-score. The results will likely show that LeNet-5 performs well on MNIST but may struggle with more complex datasets. Additionally, you can compare its performance with other modern CNN architectures to highlight its limitations on larger and more diverse datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a733e87-d9d7-491c-83ee-8781a441249b",
   "metadata": {},
   "source": [
    "### 4. `Implement LeNet-5 using a deep learning framework of your choice (e.g., TensorFlow, PyTocch) and train it on a publicly available dataset (e.g., MNIST). Evaluate its performance and provide insights.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a1f94c-793a-4399-b42f-809743d607d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to range [0, 1]\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Reshape the images to (num_samples, 28, 28, 1) as LeNet-5 takes input of size (32, 32, 1)\n",
    "train_images = tf.expand_dims(train_images, axis=-1)\n",
    "test_images = tf.expand_dims(test_images, axis=-1)\n",
    "\n",
    "# Build LeNet-5 architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(6, kernel_size=(5, 5), activation='tanh', input_shape=(28, 28, 1)),\n",
    "    layers.AveragePooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(16, kernel_size=(5, 5), activation='tanh'),\n",
    "    layers.AveragePooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(120, activation='tanh'),\n",
    "    layers.Dense(84, activation='tanh'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33e8836-728f-44b2-b133-f67c7d482eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
